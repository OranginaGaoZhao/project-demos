<!DOCTYPE html>
<html>
<title>Orange Demo</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://www.w3schools.com/lib/w3-theme-black.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<body id="myPage">

<!-- Sidebar on click -->
<nav class="w3-sidebar w3-bar-block w3-white w3-card w3-animate-left w3-xxlarge" style="display:none;z-index:2" id="mySidebar">
  <a href="javascript:void(0)" onclick="w3_close()" class="w3-bar-item w3-button w3-display-topright w3-text-teal">Close
    <i class="fa fa-remove"></i>
  </a>
  <a href="#" class="w3-bar-item w3-button">Link 1</a>
  <a href="#" class="w3-bar-item w3-button">Link 2</a>
  <a href="#" class="w3-bar-item w3-button">Link 3</a>
  <a href="#" class="w3-bar-item w3-button">Link 4</a>
  <a href="#" class="w3-bar-item w3-button">Link 5</a>
</nav>

<!-- Navbar -->
<div class="w3-top">
 <div class="w3-bar w3-theme-d2 w3-left-align">
  <a class="w3-bar-item w3-button w3-hide-medium w3-hide-large w3-right w3-hover-white w3-theme-d2" href="javascript:void(0);" onclick="openNav()"><i class="fa fa-bars"></i></a>
  <a href="#" class="w3-bar-item w3-button w3-teal"><i class="fa fa-home w3-margin-right"></i>Orange Demo</a>
  <a href="#team" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Overview</a>
  <a href="#work" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Explore</a>
  <a href="#pricing" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Download</a>
  <a href="#contact" class="w3-bar-item w3-button w3-hide-small w3-hover-white">Contact</a>
    <div class="w3-dropdown-hover w3-hide-small">
    <button class="w3-button" title="Notifications">Low Level Computer Vision<i class="fa fa-caret-down"></i></button>     
    <div class="w3-dropdown-content w3-card-4 w3-bar-block">
      <a href="#sr" class="w3-bar-item w3-button">Image Super-resolution</a>
      <a href="#demo" class="w3-bar-item w3-button">Image Demosaicking</a>
      <a href="#cc" class="w3-bar-item w3-button">Over-exposre Correction</a>
      <a href="#denoising" class="w3-bar-item w3-button">Image Denoising</a>
    </div>
    </div>
    <div class="w3-dropdown-hover w3-hide-small">
    <button class="w3-button" title="Notifications">Vision in VR/AR<i class="fa fa-caret-down"></i></button>     
    <div class="w3-dropdown-content w3-card-4 w3-bar-block">
      <a href="#gaze_tracking" class="w3-bar-item w3-button">Gaze Tracking</a>
      <a href="#depth_reconstruction" class="w3-bar-item w3-button">Depth Reconstruction</a>
      <a href="#image_synthesis" class="w3-bar-item w3-button">Image Synthesis for Virtual Camera</a>
    </div>
    </div>
  <a href="#" class="w3-bar-item w3-button w3-hide-small w3-right w3-hover-teal" title="Search"><i class="fa fa-search"></i></a>
 </div>

  <!-- Navbar on small screens -->
  <div id="navDemo" class="w3-bar-block w3-theme-d2 w3-hide w3-hide-large w3-hide-medium">
    <a href="#team" class="w3-bar-item w3-button">Team</a>
    <a href="#work" class="w3-bar-item w3-button">Work</a>
    <a href="#pricing" class="w3-bar-item w3-button">Price</a>
    <a href="#contact" class="w3-bar-item w3-button">Contact</a>
    <a href="#" class="w3-bar-item w3-button">Search</a>
  </div>
</div>

<!-- Image Header -->
<div class="w3-display-container w3-animate-opacity">
  <img src="images/FedTech-ComputerVision.jpg" alt="boat" style="width:100%;min-height:350px;max-height:600px;">
  <div class="w3-container w3-display-bottomright w3-margin-bottom ">  
    <button onclick="document.getElementById('id01').style.display='block'" class="w3-button w3-xlarge w3-theme w3-hover-teal" title="Go To W3.CSS">Deep learning for Imaging/ Computer Vision</button>
    <p style="color:lightgrey">From scientific research to commercial applications, we try to apply deep learning approaches into various computer vision tasks. We adopt convolutional neural networks on ill-posed image reconstructions problems such as: image super-resolution, image demosaicking, image denoising and over-exposure correction. Besides, we also investigate deep learning based computer vision on virtual reality and augmented reality, such as depth reconstruction, gazing tracking, eye contact on video conference and so on.</p>

  </div>
</div>


</div>

 <!-- SR Section -->
  <div id="sr" class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide">Image Super-resolution</h2>
    <p class="w3-opacity"><i># Low-level Computer Vison</i></p>
    <p class="w3-justify">We presente a simple and effective framework for image super resolution, and propose a novel CNN with a self-feature based loss network that is capable of reconstructing
    images of pleasing visual quality. We speculate that keeping consistency of features and
    network will remove the artefacts caused by features from pre-trained networks. The proposed
    use of self-feature loss approach provides new insights into designing CNNs capable
    of performing optimally in wider application areas of imaging. A new insight to designing novel loss estimation functions for deep learning architectures.</p>

    <img src="images/sr.jpg" alt="boat" style="width:100%;">
    
  </div>

 <!-- Demo Section -->
  <div id="demo" class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide">Image Demosaicking</h2>
    <p class="w3-opacity"><i># Low-level Computer Vison</i></p>
    <p class="w3-justify">A fast and flexible network, namely DemoNet, is proposed for image demosaicking. By taking a tunable CFA pattern as input, DemoNet can be generalized to any CFA pattern with a simple modification. DemoNet exhibits perceptually appealing results with the end-to-end solution, without requiring extra aid to overcome the challenging artifacts, demonstrating its potential for pratical image demosaicking. We perform in-depth analysis on the impact of different guidance prior information of CFA patterns. Our findings provide empirical knowledge on CNN architecture design for future image demosaicking research.</p>

    <img src="images/demosaick.png" alt="boat" style="width:100%;">

    <p>Hard case demo: NO salient artifacts: aliasing, zippering, false colour, blur… most all current methods prone to them.</p>
 
  </div>

   <!-- Colour Correction Section -->
  <div id="cc" class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide">Over-exposure Correction</h2>
    <p class="w3-opacity"><i># Low-level Computer Vison</i></p>
    <p class="w3-justify">Over-exposure(OE) artifact occurs when a limited dynamic range of digital imaging device records the bright scene of which luminance level is higher than saturation level of the sensor. Correcting over-exposure aims to recover the fine details from the input. Existing methods are proposed mainly from the perspective of manually image pixel manipulation, therefore often come at the cost of high computational and algorithmic complexity. Recently, some deep learning based approaches on high dynamic range (HDR) reconstruction can be treated as image correction because their output HDR image can be tone mapped into the low dynamic range (LDR) image. However, existing tone mapping methods always fail to preserve the local details from the HDR domain when OE happens. In this paper, we present OEC, a convolutional neural network (CNN) for over-exposure correction. To our knowledge, it is the first framework capable of inferring photo-realistic natural images for over-exposure in LDR domain. To achieve this, we construct a training dataset of over-exposed and ground truth image pairs for end-to-end learning. Experimental results demonstrate the advantage of our method over existing OE correction methods with a significant margin.</p>

    <img src="images/com_deep.png" alt="boat" style="width:100%;">

  </div>

  <!-- Image Denoising-->
   <div id="denoising" class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide">Image Denoising</h2>
    <p class="w3-opacity"><i># Low-level Computer Vison</i></p>
    <p class="w3-justify">A flexible denoising network, namely BiDNet, is proposed for non-blind and blind image denoising.To our best knowledge, this is the first network is adequate for those both cases and performance the state-of-the-art. We highlight CNNs are able to learn a direct mapping function instead of modeling image priors explicitly. Our model exhibits perceptually appealing results on both noisy images corrupted by AWGN and real-world noisy images, demonstrating its potential for practical image denoising.</p>

    <img src="images/denoising.png" alt="boat" style="width:100%;min-height:280px;">



    <div class="w3-row w3-padding-32">
      <p>The left is the noisy image corrupted by AWGN with noise level 75. The right is the denoised image by ours.</p>
      <div class="w3-half">
<!--    <video width="200" autoplay loop>
          <source src="images/movie.mp4" type="video/mp4">
          Your browser does not support HTML5 video.
        </video> -->
        <img src="images/test_from_FFDnet.png" alt="Flowers in Chania" style="width:85%">
      </div>

      <div class="w3-half">
<!--         <video width="200" autoplay loop>
        <source src="images/video_.mp4" type="video/mp4">
        Your browser does not support HTML5 video.
      </video> -->
      <img src="images/denoise.png" alt="Flowers in Chania" style="width:85%">
      </div>

  </div>

  <!-- Gaze Tracking Section -->
  <div id="gaze_tracking" class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide">Gaze Tracking</h2>
    <p class="w3-opacity"><i># Vison in VR/AR</i></p>
    <p class="w3-justify">Gaze tracking is a process where the eye gaze is measured to deduce where a person is looking and what element of their environment they are paying attention to. How little has been done in this area, our project focuses on this eye tracking algorithm in order to add knowledge to the development of CNNs for eye tracking. </p>

    <div class="w3-row w3-padding-32">

      <div class="w3-half">
<!--    <video width="200" autoplay loop>
          <source src="images/movie.mp4" type="video/mp4">
          Your browser does not support HTML5 video.
        </video> -->
        <img src="images/test.gif" alt="Flowers in Chania" style="width:75%">
      </div>

      <div class="w3-half">
<!--         <video width="200" autoplay loop>
        <source src="images/video_.mp4" type="video/mp4">
        Your browser does not support HTML5 video.
      </video> -->
      <img src="images/test2.gif" alt="Flowers in Chania" style="width:75%">
      </div>
    </div>
    <div class="w3-row w3-padding-32">

      <div class="w3-half">

        <img src="images/face.gif" alt="Flowers in Chania" style="width:95%">
      </div>

      <div class="w3-quarter">

      <img src="images/left_eye.gif" alt="Flowers in Chania" style="width:75%">
      </div>

      <div class="w3-quarter">

      <img src="images/right_eye.gif" alt="Flowers in Chania" style="width:75%">
      </div>

    </div>


  </div>

  <!-- Depth Reconstruction Section -->
  <div id="depth_reconstruction" class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide">Depth Reconstruction from a Single Still Image</h2>
    <p class="w3-opacity"><i># Vison in VR/AR</i></p>
    <p class="w3-justify"> 
    	Estimating depth information from single monocular images depicting general scenes is an important problem in computer vision. Many challenging computer vision problems have proven to benefit from the incorporation of depth information, to name a few, semantic labellings, pose estimations. Compared with depth estimation using multiple images such as stereo depth perception, depth from monocular images is much more challenging. Here, we present a deep convolutional neural network for estimating depths from single monocular images</p>

    <img src="images/depth_reconstruction.png" alt="boat" style="width:95%;min-height:280px;">

  </div>

   <!-- Image Synthesis Section -->
  <div id="image_synthesis" class="w3-container w3-content w3-center w3-padding-64" style="max-width:800px" id="band">
    <h2 class="w3-wide">Synthesis of Image for Virtual Camera</h2>
    <p class="w3-opacity"><i># Vison in VR/AR</i></p>
    <p class="w3-justify">We explore the capacity of CNN for occlusion handling by investigating the image synthesis for virtual cameras placed between two actual cameras. This can be applied into AR area.</p>

    <img src="images/image_synthesis.png" alt="boat" style="width:95%;min-height:280px;">

  </div>
   










<!-- Contact Container -->
<div class="w3-container w3-padding-64 w3-theme-l5" id="contact">
    <div class="w3-padding-16"><span class="w3-xlarge w3-border-teal w3-bottombar">Contact Us</span></div>
      <h3>Address</h3>
      <p>Swing by for a cup of coffee, or whatever.</p>
      <p><i class="fa fa-map-marker w3-text-teal w3-xlarge"></i>  Loughborough, UK</p>
      <p><i class="fa fa-phone w3-text-teal w3-xlarge"></i>  +44 7522121636</p>
      <p><i class="fa fa-envelope-o w3-text-teal w3-xlarge"></i>  z.gao@lboro.ac.uk</p>
</div>

<script>
// Script for side navigation
function w3_open() {
  var x = document.getElementById("mySidebar");
  x.style.width = "300px";
  x.style.paddingTop = "10%";
  x.style.display = "block";
}

// Close side navigation
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
}

// Used to toggle the menu on smaller screens when clicking on the menu button
function openNav() {
  var x = document.getElementById("navDemo");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else { 
    x.className = x.className.replace(" w3-show", "");
  }
}
</script>

</body>
</html>

